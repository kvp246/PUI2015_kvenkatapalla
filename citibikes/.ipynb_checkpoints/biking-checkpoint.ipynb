{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing whether more people ride citibike from Manhattan to Brooklyn, or from Brooklyn to Manhattan\n",
    "\n",
    "# the citibike september 2015 file can be obtained here\n",
    "# https://drive.google.com/file/d/0Bx8AmvwAoY0jUzV1dXltOXZHWTQ/view?usp=sharing\n",
    "\n",
    "Dataset: open data for citibike ridership for September 2015\n",
    "\n",
    "Idea: We want to know if the ridership from Brooklyn to Manhattan during Weekdays is Greater than that from Manhattan to Brooklyn during Weekdays.\n",
    "\n",
    "Terms: \n",
    "\n",
    "\"Manhattan\": Citibike stations in Manhattan and The Bronx\n",
    "\n",
    "\"Brooklyn\": Citibike stations in Brooklyn and Queens\n",
    "\n",
    "Control Group: People moving from Manhattan to Brooklyn\n",
    "\n",
    "Test Group: People riding from Brooklyn to Manhattan\n",
    "\n",
    "Hypotheses:\n",
    "\n",
    "Null Hypothesis: The total number of rides from Manhattan to Brooklyn on weekdays is greater than the total number of rides from Brooklyn to Manhattan on weekdays.\n",
    "\n",
    "Alternative Hypothesis: The total number of rides from Manhattan to Brooklyn on weekdays is less than or equal to the total number of rides from Brooklyn to Manhattan on weekdays.\n",
    "\n",
    "Process:\n",
    "First, we took the json file of citibike stations from the citibike database and extracted the station id, latitude and longitude. \n",
    "Then we used ArcGis to lasso around the stations in Manhattan+Bronx and add the value of 'Manhattan' against those stations in a new column entitled 'Boroughs', and we did the same for the stations in Brooklyn + Queens with the value 'Brooklyn'.\n",
    "Next, we used Python to left-join our station-borough table to the citibike csv file using the start station id and repeated the join for stop station id, and deleted the columns we did not need.\n",
    "Then we converted the starttime column into a datetime and calculated which days were weekends and which were weekdays.\n",
    "We counted the weekdays against the boroughs and performed chi-squared testing of the hypothesis.\n",
    "We got chi-squared value of 7 and rejected the null-hypothesis with a confidense of 95%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from JSON, getting a list of stations with latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing libraries to work with json, csv, url, and big data frames\n",
    "import json\n",
    "import sys\n",
    "import urllib2 as ulib\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# getting json with a list of station id, latitude, longitude\n",
    "Request = ulib.urlopen('http://www.citibikenyc.com/stations/json')\n",
    "datum= json.loads(Request.read())\n",
    "\n",
    "# exploring the json data\n",
    "bike = datum['stationBeanList']\n",
    "\n",
    "# saving the json data into the csv 'bikelist.csv'\n",
    "with open('bikelist.csv', 'wb') as CsvFile:\n",
    "    Writer = csv.writer(CsvFile)\n",
    "    Headers = ['station id', 'latitude', 'longitude']\n",
    "    Writer.writerow(Headers)\n",
    "\n",
    "    for station in bike:\n",
    "        Writer.writerow([station['id'], station['latitude'], station['longitude']])        \n",
    "\n",
    "# After that we split all the stations into the Manhattan ones and Brooklyn ones\n",
    "# We used ArcGis Map for that.\n",
    "# the resulting file is StationsBorough.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining table of stations and boroughs to citibike dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 40, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c816bf73a637>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reading Citibike data for September 2015 into citibike015 and the generated table of station ids and their boroughs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboroughs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'StationsBorough.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# the file can be obtained here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://drive.google.com/file/d/0Bx8AmvwAoY0jUzV1dXltOXZHWTQ/view?usp=sharing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcitibike0915\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bike.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m _parser_defaults = {\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    719\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7544)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:7784)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:8401)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:8275)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:20691)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 40, saw 3\n"
     ]
    }
   ],
   "source": [
    "# reading Citibike data for September 2015 into citibike015 and the generated table of station ids and their boroughs\n",
    "boroughs = pd.read_csv('StationsBorough.csv')\n",
    "# the file can be obtained here\n",
    "# https://drive.google.com/file/d/0Bx8AmvwAoY0jUzV1dXltOXZHWTQ/view?usp=sharing\n",
    "citibike0915 = pd.read_csv('bike.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performing left join of the station id table to the original citibike table to \n",
    "# identify where the stations are: in Brooklyn or in Manhattan:\n",
    "# by starting station\n",
    "citibike0915=citibike0915.merge(boroughs, left_on='start station id', right_on='id', how='left', sort=False)\n",
    "\n",
    "#  cleaning data and renaming the adjoined columns\n",
    "citibike0915.drop(['bikeid', 'usertype', 'gender', 'tripduration', 'stoptime', 'start station name', 'birth year', 'end station name', 'id'], axis=1, inplace=True)\n",
    "citibike0915.rename(columns = {'Borough':'Start Borough'}, inplace=True)\n",
    "\n",
    "# performing left join of the station id table to the original citibike table to \n",
    "# identify where the stations are: in Brooklyn or in Manhattan:\n",
    "# by starting station\n",
    "citibike0915=citibike0915.merge(boroughs, left_on='end station id', right_on='id', how='left', sort=False)\n",
    "\n",
    "# cleaning data and renaming the adjoined columns\n",
    "citibike0915.drop('id', axis=1, inplace=True)\n",
    "citibike0915.rename(columns = {'Borough':'End Borough'}, inplace=True)\n",
    "\n",
    "# converting the starttime field from string to datetime\n",
    "citibike0915['starttime'] = pd.to_datetime(citibike0915['starttime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting trips in each direction between the boroughs against the weekdays and weekends. Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to calculate if a given date is a weekday, or a weekend\n",
    "def Weekend(x):\n",
    "    if x.weekday() > 5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# checking if a start time of the trip is a weekend\n",
    "citibike0915['weekend'] = citibike0915['starttime'].apply(lambda x: Weekend(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            starttime  start station id  start station latitude  \\\n",
      "0 2015-09-01 00:00:00               263               40.717290   \n",
      "1 2015-09-01 00:00:00               495               40.762699   \n",
      "2 2015-09-01 00:00:01              3119               40.742327   \n",
      "3 2015-09-01 00:00:07               536               40.741444   \n",
      "4 2015-09-01 00:00:09               347               40.728846   \n",
      "\n",
      "   start station longitude  end station id  end station latitude  \\\n",
      "0               -73.996375             307             40.714275   \n",
      "1               -73.993012             449             40.764618   \n",
      "2               -73.954117            3118             40.735550   \n",
      "3               -73.975361             340             40.712690   \n",
      "4               -74.008591             483             40.732233   \n",
      "\n",
      "   end station longitude Start Borough End Borough weekend  \n",
      "0             -73.989900     Manhattan   Manhattan   False  \n",
      "1             -73.987895     Manhattan   Manhattan   False  \n",
      "2             -73.952840      Brooklyn    Brooklyn   False  \n",
      "3             -73.987763     Manhattan   Manhattan   False  \n",
      "4             -73.988900     Manhattan   Manhattan   False  \n"
     ]
    }
   ],
   "source": [
    "print(citibike0915.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekend  Start Borough  End Borough\n",
       "False    Brooklyn       Brooklyn        97429\n",
       "                        Manhattan       23952\n",
       "         Manhattan      Brooklyn        25568\n",
       "                        Manhattan      989467\n",
       "True     Brooklyn       Brooklyn        17655\n",
       "                        Manhattan        3716\n",
       "         Manhattan      Brooklyn         3838\n",
       "                        Manhattan      120147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting how many trips happened on a weekday (weekend = false), depending on the direction of the trip:\n",
    "# Brooklyn to Manhattan or Manhattan to Brooklyn\n",
    "citibike0915.groupby(['weekend', 'Start Borough', 'End Borough']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the hypothesis. Performing chi-squared and z-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared statistics is  7\n"
     ]
    }
   ],
   "source": [
    "# Performing the chi-square test\n",
    "# Total Frequency\n",
    "Tot_MB_Grp = 29406\n",
    "Tot_BM_Grp = 27668\n",
    "\n",
    "# Weekday frequency of MB\n",
    "Tot_MBWD_Grp = 25568\n",
    "Tot_MBWE_Grp = Tot_MB_Grp - Tot_MBWD_Grp\n",
    "\n",
    "# Weekday frequency of BM\n",
    "Tot_BMWD_Grp = 23952\n",
    "Tot_BMWE_Grp = Tot_BM_Grp - Tot_BMWD_Grp\n",
    "\n",
    "# Assigning values to chi-square notation\n",
    "a = Tot_MBWD_Grp\n",
    "b = Tot_BMWD_Grp\n",
    "c = Tot_MBWE_Grp\n",
    "d = Tot_MBWE_Grp\n",
    "\n",
    "# Computing chi-square statistic\n",
    "Ntot = a + b + c + d\n",
    "expected = (a + b)*(c + d)*(a + c)*(b + d)\n",
    "sample_values = [[a,b],[c,d]]\n",
    " \n",
    "chisqstat= lambda N, values, expect : N*((values[0][0]*values[1][1]-values[0][1]*values[1][0])**2)/(expect)\n",
    "\n",
    "# Printing the chi-square statistic value\n",
    "print \"Chi-squared statistics is \", chisqstat(Ntot,  sample_values, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared statistics is 7, therefore we reject the null hypothesis with a 95% confidense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434253862862\n",
      "z score  -9.97585786394\n",
      "is the p value 0.09 smaller than the critical value 0.05? \n",
      "NO!\n",
      "the Null hypothesis is not rejected\n"
     ]
    }
   ],
   "source": [
    "# Z-test\n",
    "\n",
    "#Rides from Brooklyn to Manhattan on weekdays\n",
    "P_0 = 25568.0 / 57074.0\n",
    "#Rides from Manhattan to Brooklyn on weekdays\n",
    "P_1 = 23952.0 / 57074.0\n",
    "\n",
    "#Total number of rides to Manhattan and Brooklyn (Sample Size)\n",
    "n_0=29406.0\n",
    "n_1=27668.0\n",
    "\n",
    "#lets get the counts by multiplying by the sample size\n",
    "Nt_0=25568.0\n",
    "Nt_1=23952.0\n",
    "\n",
    "sp=((P_0*n_0)+(P_1*n_1))/(n_1+n_0)\n",
    "print sp\n",
    "\n",
    "sp_stdev= lambda p, n: np.sqrt( p * ( 1 - p ) /n[0] +  p * ( 1 - p )/n[1]  )\n",
    "\n",
    "\n",
    "sp_stdev_2y=sp_stdev((Nt_0+Nt_1)/(n_0+n_1),[n_0,n_1])\n",
    "\n",
    "zscore = lambda p0, p1, s : (p0-p1)/s\n",
    "z_2y = zscore(P_1, P_0, sp_stdev_2y)\n",
    "print \"z score \", z_2y\n",
    "\n",
    "p_2y=1-0.9115\n",
    "\n",
    "alpha = 0.05\n",
    "def report_result(p,a):\n",
    "    print 'is the p value {0:.2f} smaller than the critical value {1:.2f}? '.format(p,a)\n",
    "    if p<a:\n",
    "        print \"YES!\"\n",
    "    else: print \"NO!\"\n",
    "    \n",
    "    print 'the Null hypothesis is {}'.format( 'rejected' if p<a  else 'not rejected') \n",
    "\n",
    "    \n",
    "report_result(p_2y,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z score is -9.98, therefore the Null hypothesis is rejected with a 95% confidense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
